# AI短剧生成项目分析

> 分析日期：2026-01-25
> 目的：寻找完整剧情生成工作流的启发

---

## 一、火宝短剧 (huobao-drama)

**仓库地址**：https://github.com/chatfire-AI/huobao-drama

### 项目定位

"一句话生成完整短剧" —— 从用户输入的一句话，自动生成完整的短剧视频。

### 核心架构

```
用户输入（一句话）
    ↓
剧情生成（LLM）
    ↓
分镜脚本（场景+台词+动作）
    ↓
素材生成
├── 图像生成（角色+场景）
├── 语音合成（TTS）
└── 视频生成（图生视频）
    ↓
视频合成（拼接+字幕+音效）
    ↓
完整短剧输出
```

### 关键技术点

| 模块 | 技术方案 |
|------|----------|
| 剧情生成 | GPT-4 / Claude，使用 Jinja2 模板管理 Prompt |
| 图像生成 | Midjourney / DALL-E / Stable Diffusion |
| 语音合成 | 多家 TTS 接入（支持克隆音色） |
| 视频生成 | Runway / Pika / MiniMax |
| 任务调度 | Celery 异步队列 |
| 存储 | 阿里云 OSS / S3 |

### Prompt 设计（重点参考）

**剧情生成 Prompt 模板结构**：

```
角色定义：
- 主角设定（性格、外形、口头禅）
- 配角设定
- 角色关系

故事要求：
- 主题/类型（搞笑/悬疑/感人）
- 时长限制（30秒/1分钟）
- 分镜数量（3-5个）

输出格式：
- 结构化 JSON
- 每个分镜包含：场景描述、角色动作、台词、时长
```

**分镜脚本 JSON 示例**：

```json
{
  "title": "暴发户买画",
  "scenes": [
    {
      "scene_id": 1,
      "duration": 10,
      "setting": "街头漫步",
      "characters": ["橘猫", "贵宾"],
      "dialogue": [
        {"character": "橘猫", "line": "媳妇儿，我今天买了幅画！"},
        {"character": "贵宾", "line": "啥画？"}
      ],
      "action": "两人并肩走在街头，橘猫得意地比划",
      "camera": "中景跟拍，背景移动"
    }
  ]
}
```

### 对我们的启发

1. **Prompt 模板化**：用 Jinja2 管理不同场景的 Prompt，复用性强
2. **结构化输出**：让 LLM 输出 JSON，便于后续自动化处理
3. **角色一致性**：在 Prompt 中强调角色外形描述，保持生成一致性
4. **异步处理**：视频生成耗时长，用队列管理任务状态

---

## 二、ai_story

**仓库地址**：https://github.com/xhongc/ai_story

### 项目定位

AI短剧自动化生成工具，支持从剧本到成片的完整流程。

### 核心架构

```
剧本输入（手写/AI生成）
    ↓
剧本解析（提取场景+台词）
    ↓
资源调度
├── 角色图片库（预设/生成）
├── 场景图片库
└── 音效库
    ↓
生成 Pipeline
├── 图片选择/生成
├── TTS 语音
├── 图生视频
└── 音视频合成
    ↓
导出成片
```

### 技术架构（DDD 领域驱动设计）

```
ai_story/
├── domain/           # 领域层
│   ├── story/        # 故事领域
│   ├── character/    # 角色领域
│   └── scene/        # 场景领域
├── application/      # 应用层（用例）
├── infrastructure/   # 基础设施
│   ├── llm/          # LLM 接口
│   ├── tts/          # TTS 接口
│   └── video/        # 视频生成接口
└── interface/        # 接口层（API/CLI）
```

### 关键设计

| 概念 | 说明 |
|------|------|
| Story | 完整故事对象，包含多个 Scene |
| Scene | 场景对象，包含角色、台词、时长 |
| Character | 角色对象，包含外形描述、声音ID |
| Asset | 资源对象（图片/音频/视频） |

### 剧本格式（Markdown）

```markdown
# 第一集：街头漫步

## 场景1：街头
时长：10秒
角色：橘猫、贵宾

**橘猫**：媳妇儿，我今天买了幅画！
**贵宾**：啥画这么贵？

动作：两人并肩行走，背景是繁华街道
```

### 对我们的启发

1. **Markdown 剧本**：比 JSON 更易读易写，人工可直接编辑
2. **角色资源库**：预先准备角色的多种姿态图片，减少生成次数
3. **场景复用**：同一场景多次使用，不重复生成
4. **模块化接口**：LLM/TTS/视频生成抽象为接口，易于替换供应商

---

## 三、两个项目对比

| 维度 | 火宝短剧 | ai_story |
|------|----------|----------|
| 输入方式 | 一句话自动生成 | 手写剧本 + AI辅助 |
| 剧本格式 | JSON | Markdown |
| 架构风格 | Pipeline 流程式 | DDD 领域驱动 |
| 角色管理 | 每次生成 | 资源库复用 |
| 适合场景 | 快速原型、批量生成 | 精细制作、迭代调整 |

---

## 四、我们可以借鉴的设计

### 1. 剧本结构（推荐 Markdown + 元数据）

```markdown
---
title: 第一集：买画
characters:
  - name: 橘猫
    voice_id: shehui_dage_jumu_002
    description: 穿LV皮夹克的富态橘猫
  - name: 贵宾
    voice_id: guibin_xiaojie_001
    description: 金色比基尼的高挑贵宾犬
---

## V1（0-10秒）
场景：街头漫步
机位：中景跟拍，背景移动

**橘猫**：媳妇儿，我今天买了幅画，八百万！
**贵宾**：啥画这么贵？
```

### 2. 角色一致性控制

在 Prompt 中加入硬性约束：

```
【角色约束】
- 画面中必须始终包含两个角色
- 禁止任何角色离开画面边界
- 使用"camera follows"而非"character walks"
- 如发现角色数量变化，立即停止并重新生成
```

### 3. 生成状态管理

```
状态：待生成 → 生成中 → 生成完成 → 合成中 → 完成
     ↓
   生成失败 → 重试（最多3次）→ 人工介入
```

### 4. 成本控制策略

| 策略 | 说明 |
|------|------|
| 512P 实验 | 先用低分辨率验证效果 |
| 批量生成 | 同一场景多段一起提交 |
| 缓存复用 | 相同 Prompt 不重复生成 |
| 人工预审 | 图片生成后人工确认再生成视频 |

---

## 五、建议的工作流优化

```
Step 1: 角色设定（一次性）
├── 外形描述
├── 声音克隆 ✅ 已完成
├── 起始帧图片 ✅ 已有
└── 固定 Prompt 模板

Step 2: 剧本创作
├── 写分镜剧本（Markdown格式）
├── 标注时长、机位、动作
└── 人工审核确认

Step 3: 语音生成
├── 提取台词
├── 调用 MiniMax TTS
└── 保存音频文件

Step 4: 视频生成（核心）
├── 使用起始帧
├── Prompt 包含角色约束
├── 512P 低成本测试
└── 确认效果后升级分辨率

Step 5: 合成输出
├── 音视频对齐
├── 添加字幕
├── 背景音乐
└── 导出成品
```

---

## 六、下一步行动

1. **完善角色人设**：填写 `角色人设.md` 中的待补充内容
2. **制定 Prompt 模板**：基于角色描述创建固定模板
3. **测试生成流程**：用第一个分镜测试完整流程
4. **迭代优化**：根据效果调整 Prompt 和参数

---

*分析完成：2026-01-25*
